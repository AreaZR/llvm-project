; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 4
; RUN: llc -o - %s | FileCheck %s
target triple = "aarch64--"

declare void @begin()
declare void @end()

; Test that we use the zero register before regalloc and do not unnecessarily
; clobber a register with the SUBS (cmp) instruction.
; CHECK-LABEL: func:
define void @func(ptr %addr) {
  ; We should not see any spills or reloads between begin and end
; CHECK-LABEL: func:
; CHECK:       // %bb.0:
; CHECK-NEXT:    stp x29, x30, [sp, #-96]! // 16-byte Folded Spill
; CHECK-NEXT:    stp x28, x27, [sp, #16] // 16-byte Folded Spill
; CHECK-NEXT:    stp x26, x25, [sp, #32] // 16-byte Folded Spill
; CHECK-NEXT:    stp x24, x23, [sp, #48] // 16-byte Folded Spill
; CHECK-NEXT:    stp x22, x21, [sp, #64] // 16-byte Folded Spill
; CHECK-NEXT:    stp x20, x19, [sp, #80] // 16-byte Folded Spill
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    .cfi_offset w19, -8
; CHECK-NEXT:    .cfi_offset w20, -16
; CHECK-NEXT:    .cfi_offset w21, -24
; CHECK-NEXT:    .cfi_offset w22, -32
; CHECK-NEXT:    .cfi_offset w23, -40
; CHECK-NEXT:    .cfi_offset w24, -48
; CHECK-NEXT:    .cfi_offset w25, -56
; CHECK-NEXT:    .cfi_offset w26, -64
; CHECK-NEXT:    .cfi_offset w27, -72
; CHECK-NEXT:    .cfi_offset w28, -80
; CHECK-NEXT:    .cfi_offset w30, -88
; CHECK-NEXT:    .cfi_offset w29, -96
; CHECK-NEXT:    mov x19, x0
; CHECK-NEXT:    bl begin
; CHECK-NEXT:    ldr x8, [x19]
; CHECK-NEXT:    ldr x9, [x19]
; CHECK-NEXT:    ldr x10, [x19]
; CHECK-NEXT:    ldr x11, [x19]
; CHECK-NEXT:    ldr x12, [x19]
; CHECK-NEXT:    ldr x13, [x19]
; CHECK-NEXT:    cmp x8, x9
; CHECK-NEXT:    ldr x14, [x19]
; CHECK-NEXT:    ldr x15, [x19]
; CHECK-NEXT:    ldr x16, [x19]
; CHECK-NEXT:    ldr x17, [x19]
; CHECK-NEXT:    ldr x18, [x19]
; CHECK-NEXT:    ldr x0, [x19]
; CHECK-NEXT:    ldr x1, [x19]
; CHECK-NEXT:    ldr x2, [x19]
; CHECK-NEXT:    ldr x3, [x19]
; CHECK-NEXT:    ldr x4, [x19]
; CHECK-NEXT:    ldr x5, [x19]
; CHECK-NEXT:    ldr x6, [x19]
; CHECK-NEXT:    ldr x7, [x19]
; CHECK-NEXT:    ldr x20, [x19]
; CHECK-NEXT:    ldr x21, [x19]
; CHECK-NEXT:    ldr x22, [x19]
; CHECK-NEXT:    ldr x23, [x19]
; CHECK-NEXT:    ldr x24, [x19]
; CHECK-NEXT:    ldr x25, [x19]
; CHECK-NEXT:    ldr x26, [x19]
; CHECK-NEXT:    ldr x27, [x19]
; CHECK-NEXT:    ldr x28, [x19]
; CHECK-NEXT:    ldr x29, [x19]
; CHECK-NEXT:    ldr x30, [x19]
; CHECK-NEXT:    b.ne .LBB0_2
; CHECK-NEXT:  // %bb.1: // %if.then
; CHECK-NEXT:    str x10, [x19]
; CHECK-NEXT:  .LBB0_2: // %if.end
; CHECK-NEXT:    str x8, [x19]
; CHECK-NEXT:    str x9, [x19]
; CHECK-NEXT:    str x10, [x19]
; CHECK-NEXT:    str x11, [x19]
; CHECK-NEXT:    str x12, [x19]
; CHECK-NEXT:    str x13, [x19]
; CHECK-NEXT:    str x14, [x19]
; CHECK-NEXT:    str x15, [x19]
; CHECK-NEXT:    str x16, [x19]
; CHECK-NEXT:    str x17, [x19]
; CHECK-NEXT:    str x18, [x19]
; CHECK-NEXT:    str x0, [x19]
; CHECK-NEXT:    str x1, [x19]
; CHECK-NEXT:    str x2, [x19]
; CHECK-NEXT:    str x3, [x19]
; CHECK-NEXT:    str x4, [x19]
; CHECK-NEXT:    str x5, [x19]
; CHECK-NEXT:    str x6, [x19]
; CHECK-NEXT:    str x7, [x19]
; CHECK-NEXT:    str x20, [x19]
; CHECK-NEXT:    str x21, [x19]
; CHECK-NEXT:    str x22, [x19]
; CHECK-NEXT:    str x23, [x19]
; CHECK-NEXT:    str x24, [x19]
; CHECK-NEXT:    str x25, [x19]
; CHECK-NEXT:    str x26, [x19]
; CHECK-NEXT:    str x27, [x19]
; CHECK-NEXT:    str x28, [x19]
; CHECK-NEXT:    str x29, [x19]
; CHECK-NEXT:    str x30, [x19]
; CHECK-NEXT:    bl end
; CHECK-NEXT:    ldp x20, x19, [sp, #80] // 16-byte Folded Reload
; CHECK-NEXT:    ldp x22, x21, [sp, #64] // 16-byte Folded Reload
; CHECK-NEXT:    ldp x24, x23, [sp, #48] // 16-byte Folded Reload
; CHECK-NEXT:    ldp x26, x25, [sp, #32] // 16-byte Folded Reload
; CHECK-NEXT:    ldp x28, x27, [sp, #16] // 16-byte Folded Reload
; CHECK-NEXT:    ldp x29, x30, [sp], #96 // 16-byte Folded Reload
; CHECK-NEXT:    ret
  call void @begin()
  %v0 = load volatile i64, ptr %addr
  %v1 = load volatile i64, ptr %addr
  %v2 = load volatile i64, ptr %addr
  %v3 = load volatile i64, ptr %addr
  %v4 = load volatile i64, ptr %addr
  %v5 = load volatile i64, ptr %addr
  %v6 = load volatile i64, ptr %addr
  %v7 = load volatile i64, ptr %addr
  %v8 = load volatile i64, ptr %addr
  %v9 = load volatile i64, ptr %addr
  %v10 = load volatile i64, ptr %addr
  %v11 = load volatile i64, ptr %addr
  %v12 = load volatile i64, ptr %addr
  %v13 = load volatile i64, ptr %addr
  %v14 = load volatile i64, ptr %addr
  %v15 = load volatile i64, ptr %addr
  %v16 = load volatile i64, ptr %addr
  %v17 = load volatile i64, ptr %addr
  %v18 = load volatile i64, ptr %addr
  %v19 = load volatile i64, ptr %addr
  %v20 = load volatile i64, ptr %addr
  %v21 = load volatile i64, ptr %addr
  %v22 = load volatile i64, ptr %addr
  %v23 = load volatile i64, ptr %addr
  %v24 = load volatile i64, ptr %addr
  %v25 = load volatile i64, ptr %addr
  %v26 = load volatile i64, ptr %addr
  %v27 = load volatile i64, ptr %addr
  %v28 = load volatile i64, ptr %addr
  %v29 = load volatile i64, ptr %addr

  %c = icmp eq i64 %v0, %v1
  br i1 %c, label %if.then, label %if.end

if.then:
  store volatile i64 %v2, ptr %addr
  br label %if.end

if.end:
  store volatile i64 %v0, ptr %addr
  store volatile i64 %v1, ptr %addr
  store volatile i64 %v2, ptr %addr
  store volatile i64 %v3, ptr %addr
  store volatile i64 %v4, ptr %addr
  store volatile i64 %v5, ptr %addr
  store volatile i64 %v6, ptr %addr
  store volatile i64 %v7, ptr %addr
  store volatile i64 %v8, ptr %addr
  store volatile i64 %v9, ptr %addr
  store volatile i64 %v10, ptr %addr
  store volatile i64 %v11, ptr %addr
  store volatile i64 %v12, ptr %addr
  store volatile i64 %v13, ptr %addr
  store volatile i64 %v14, ptr %addr
  store volatile i64 %v15, ptr %addr
  store volatile i64 %v16, ptr %addr
  store volatile i64 %v17, ptr %addr
  store volatile i64 %v18, ptr %addr
  store volatile i64 %v19, ptr %addr
  store volatile i64 %v20, ptr %addr
  store volatile i64 %v21, ptr %addr
  store volatile i64 %v22, ptr %addr
  store volatile i64 %v23, ptr %addr
  store volatile i64 %v24, ptr %addr
  store volatile i64 %v25, ptr %addr
  store volatile i64 %v26, ptr %addr
  store volatile i64 %v27, ptr %addr
  store volatile i64 %v28, ptr %addr
  store volatile i64 %v29, ptr %addr
  call void @end()

  ret void
}
